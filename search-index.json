[{"content":"","date":"2023-09-07","id":0,"permalink":"/docs/guides/","summary":"","tags":[],"title":"Guides"},{"content":"云原生技术探索。\n","date":"2023-09-07","id":1,"permalink":"/docs/cloud/introduction/","summary":"云原生技术探索。","tags":[],"title":"Introduction"},{"content":"卫星实验室，一个专注于研究卫星以及 CRM 的开源组织。\n此项目为卫星实验室主页 xlabs.club 的源码，记录常用文档和零碎博客，欢迎提交 PR 开源共建。\n本地开发 本项目使用 Hugo 开发，使用 Doks 作为 Hugo 主题。\n本地开发时先安装 Nodejs，然后使用 pnpm（或 npm） 安装 Hugo bin，本地不需要提前安装 Hugo。\n# 安装 npm 依赖包，注意网络连接 pnpm install # 启动 Web，然后浏览器访问 http://localhost:1313/即可浏览效果 pnpm run dev # 代码提交前先检查 pnpm run lint # 编译结果 pnpm run build # 创建新页面 pnpm run create docs/guides/faq.md pnpm run create blog/k8s.md License 本文档采用 CC BY-NC 4.0 许可协议。\n","date":"2023-09-07","id":2,"permalink":"/docs/guides/introduction/","summary":"卫星实验室，一个专注于研究卫星以及 CRM 的开源组织。\n此项目为卫星实验室主页 xlabs.club 的源码，记录常用文档和零碎博客，欢迎提交 PR 开源共建。\n本地开发 本项目使用 Hugo 开发，使用 Doks 作为 Hugo 主题。\n本地开发时先安装 Nodejs，然后使用 pnpm（或 npm） 安装 Hugo bin，本地不需要提前安装 Hugo。\n# 安装 npm 依赖包，注意网络连接 pnpm install # 启动 Web，然后浏览器访问 http://localhost:1313/即可浏览效果 pnpm run dev # 代码提交前先检查 pnpm run lint # 编译结果 pnpm run build # 创建新页面 pnpm run create docs/guides/faq.md pnpm run create blog/k8s.md License 本文档采用 CC BY-NC 4.0 许可协议。","tags":[],"title":"Introduction"},{"content":"我们的平台工程建设之路。\n","date":"2023-09-07","id":3,"permalink":"/docs/platform/introduction/","summary":"我们的平台工程总体架构","tags":[],"title":"总体架构"},{"content":"我们的平台工程建设之路。\n","date":"2023-09-07","id":4,"permalink":"/docs/platform/","summary":"我们的平台工程建设之路。","tags":[],"title":"平台工程"},{"content":"云原生技术探索。\n","date":"2023-09-07","id":5,"permalink":"/docs/cloud/","summary":"云原生技术探索。","tags":[],"title":"云原生"},{"content":"我有一个 Spring Boot 应用服务，提供了一些简单的查询接口，本身运行很正常，通过 curl 或其他 http 客户端 localhost 请求都没有问题。\n某天通过 Traefik 代理了此服务，经过代理后再访问，某个接口一直都是 500 internal server error，其他接口都没有问题。通过 tcpdump 抓包发现，应用服务并没有返回任何 500 错误，而且 Traefik 本身也没有错误日志。\n根据网上经验排查了 Traefik SSL 证书问题、路径问题、消息体太大问题、请求 Header 不合规问题，都一一否定。最后无意间看了一眼 Response Header，发现 Spring Boot 应用返回了两个 Transfer-Encoding: chunked Header。\n再根据此 Header 搜索，发现果然有人遇到过类似问题，请参考这几个链接。\nhttps://github.com/traefik/traefik/issues/7741 https://github.com/spring-projects/spring-framework/issues/21523 https://github.com/spring-projects/spring-boot/issues/37646 https://stackoverflow.com/questions/77042701/nginx-upstream-sent-duplicate-header-line-transfer-encoding-chunked-previo 从上面链接描述中可知，不仅 Traefik 会出现此问题，nginx 包含以 nginx 为基础的 ingress 也会出现同样问题，不过 nginx 返回错误码是 502。\n我所使用的 Traefik(2.10.x) 和 Spring Boot(2.7.x) 都是当前日期最新版本，目前仍然有问题。\n出现此问题的代码类似如下。\nimport org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.client.RestTemplate; @Controller @RequestMapping(\u0026#34;/status\u0026#34;) public class StatusController { @Autowired private RestTemplate restTemplate; @GetMapping(value = \u0026#34;/test\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; getStatus() { return restTemplate.getForEntity(\u0026#34;http://another-service/actuator/health\u0026#34;, String.class); } } 修改为如下方式即解决问题。\nimport org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.client.RestTemplate; @Controller @RequestMapping(\u0026#34;/status\u0026#34;) public class StatusController { @Autowired private RestTemplate restTemplate; @GetMapping(value = \u0026#34;/test\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; getStatus() { // 不要直接用 RestTemplate 返回值，使用 ResponseEntity 重新包装一次 return ResponseEntity.ok(restTemplate.getForEntity(\u0026#34;http://another-service/actuator/health\u0026#34;, String.class)); } } 另外根据 GitHub Issue 反馈，不仅 RestTemplate，使用 OpenFeign 也会触发以上问题。\n同理，如果大家遇到服务经过 Nginx、Traefik 代理后出现的疑难问题，可关注下 Response Header 是否有异常。\n","date":"2023-11-26","id":6,"permalink":"/blog/duplicate-transfer-encoding-chunked/","summary":"我有一个 Spring Boot 应用服务，提供了一些简单的查询接口，本身运行很正常，通过 curl 或其他 http 客户端 localhost 请求都没有问题。\n某天通过 Traefik 代理了此服务，经过代理后再访问，某个接口一直都是 500 internal server error，其他接口都没有问题。通过 tcpdump 抓包发现，应用服务并没有返回任何 500 错误，而且 Traefik 本身也没有错误日志。\n根据网上经验排查了 Traefik SSL 证书问题、路径问题、消息体太大问题、请求 Header 不合规问题，都一一否定。最后无意间看了一眼 Response Header，发现 Spring Boot 应用返回了两个 Transfer-Encoding: chunked Header。\n再根据此 Header 搜索，发现果然有人遇到过类似问题，请参考这几个链接。\nhttps://github.com/traefik/traefik/issues/7741 https://github.com/spring-projects/spring-framework/issues/21523 https://github.com/spring-projects/spring-boot/issues/37646 https://stackoverflow.com/questions/77042701/nginx-upstream-sent-duplicate-header-line-transfer-encoding-chunked-previo 从上面链接描述中可知，不仅 Traefik 会出现此问题，nginx 包含以 nginx 为基础的 ingress 也会出现同样问题，不过 nginx 返回错误码是 502。\n我所使用的 Traefik(2.10.x) 和 Spring Boot(2.7.x) 都是当前日期最新版本，目前仍然有问题。\n出现此问题的代码类似如下。\nimport org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.","tags":["Java"],"title":"重复 Transfer-Encoding Header 引起的服务 500 问题"},{"content":"","date":"2023-09-07","id":7,"permalink":"/blog/","summary":"","tags":[],"title":"Blog"},{"content":"问题描述：\n一个 Java 应用跑在 K8S 容器内，Pod 内只有 Java 这一个进程。应用跑了一段时间后，CPU、内存占用都不高，但是却出现以下 OutOfMemoryError 错误。\nException in thread \u0026#34;slow-fetch-15\u0026#34; java.lang.OutOfMemoryError: unable to create new native thread 428 at java.lang.Thread.start0(Native Method) 429 at java.lang.Thread.start(Thread.java:719) 430 at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957) 431 at java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1025) 432 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167) 433 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 进入 Pod 内，尝试执行任何操作，又会出现 unable to start container process 错误。\n一开始怀疑是内存不足，调大了内存，同时也缩小了 Java 的 xss， 都不起作用。\n真实原因： K8S 容器限制了 PID 数，无法创建新的线程，在 Pod 内 cat /sys/fs/cgroup/pids/pids.max 发现是 1024。\n关于 K8S pid limit， 可参考此资料：https://kubernetes.io/zh-cn/docs/concepts/policy/pid-limiting/.\n但是，PID 为什么会超呢，Pod 内只有一个 Java 进程，PID 数不应该是 1 个吗，这个 PID 限制为什么影响了线程。\n简单来讲，在 Linux 中线程其实是通过轻量级进程实现的，也就是 LWP(light weight process)，因此在 Linux 中每个线程都是一个进程，都拥有一个 PID，换句话说，操作系统原理中的线程，对应的其实是 Linux 中的进程（即 LWP），因此 Linux 内核中的 PID 对应的其实是原理中的 TID。\n在 Pod 内通过 top -p pid -H 查看，可以看到第一列每个线程都分配了一个 PID。\nPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 101 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:16.29 VM Thread 112 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:46.13 C2 CompilerThre 113 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:39.62 C1 CompilerThre 846 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:00.64 NettyClientSele 850 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:00.54 NettyClientWork 1 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.27 java 89 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.99 java 90 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.29 java 91 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.27 java 92 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.26 java 93 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.30 java 94 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:01.43 java 95 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.11 java 96 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.12 java 97 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.16 java 98 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.31 java 99 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.32 java 为什么要限制 POD PID 数。类似 CPU 和内存，进程 ID（PID）也是节点上的一种基础资源，很容易就会在尚未超出其它资源约束的时候就已经触及任务个数上限，进而导致宿主机不稳定。某日某个不起眼的服务因为无节制创建了 N 多线程，把整个宿主机打挂了，谁痛谁知道啊。\n","date":"2023-09-07","id":8,"permalink":"/blog/k8s-pid-limiting-oom/","summary":"问题描述：\n一个 Java 应用跑在 K8S 容器内，Pod 内只有 Java 这一个进程。应用跑了一段时间后，CPU、内存占用都不高，但是却出现以下 OutOfMemoryError 错误。\nException in thread \u0026#34;slow-fetch-15\u0026#34; java.lang.OutOfMemoryError: unable to create new native thread 428 at java.lang.Thread.start0(Native Method) 429 at java.lang.Thread.start(Thread.java:719) 430 at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957) 431 at java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1025) 432 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167) 433 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 进入 Pod 内，尝试执行任何操作，又会出现 unable to start container process 错误。\n一开始怀疑是内存不足，调大了内存，同时也缩小了 Java 的 xss， 都不起作用。\n真实原因： K8S 容器限制了 PID 数，无法创建新的线程，在 Pod 内 cat /sys/fs/cgroup/pids/pids.max 发现是 1024。\n关于 K8S pid limit， 可参考此资料：https://kubernetes.","tags":["k8s","Java"],"title":"K8S 容器 PID 限制引起的 OOM"},{"content":"故事背景：\n一个 K8S Pod，里面只有一个 Java 进程，K8S request 和 limit memory 都是 2G，Java 进程核心参数包括：-XX:+UseZGC -Xmx1024m -Xms768m -XX:SoftMaxHeapSize=512m。\n服务启动一段时间后，查看 Grafana 监控数据，Pod 内存使用量约 1.5G，JVM 内存使用量约 500M，通过 jvm dump 分析没有任何大对象，运行三五天后出现 ContainerOOM。\n首先区分下 ContainerOOM 和 JvmOOM，ContainerOOM 是 Pod 内存不够，Java 向操作系统申请内存时内存不足导致。\n问题来了：\nPod 2G 内存，JVM 设置了 Xmx 1G，已经预留了 1G 内存，为什么还会 ContainerOOM，这预留的 1G 内存被谁吃了。 正常情况下（无 ContainerOOM），Grafana 看到的监控数据，Pod 内存使用量 1.5G， JVM 内存使用量 500M，差别为什么这么大。 Grafana 看到的监控数据，内存使用量、提交量各是什么意思，这些值是怎么算出来的，和 Pod 进程中如何对应，为什么提交量一直居高不小。 Grafana 监控图。\n统计指标 Pod 内存使用量统计的指标是 container_memory_working_set_bytes：\ncontainer_memory_usage_bytes = container_memory_rss + container_memory_cache + kernel memory container_memory_working_set_bytes = container_memory_usage_bytes - total_inactive_file（未激活的匿名缓存页） container_memory_working_set_bytes 是容器真实使用的内存量，也是资源限制 limit 时的 OOM 判断依据。\n另外注意 cgroup 版本差异： container_memory_cache reflects cache (cgroup v1) or file (cgroup v2) entry in memory.stat.\nJVM 内存使用量统计的指标是 jvm_memory_bytes_used： heap、non-heap 以及其他 真实用量总和。下面解释其他。\n对比一下 top 命令，使用 top 命令看一下 Java 进程真正占了多少。\ntop -p $(pgrep java) # 注意下面的数据和截图不是同一时间的 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 7 root 20 0 58.2g 1.6g 1.0g S 17.3 2.3 659:42.46 java VIRT：virtual memory usage 虚拟内存\n进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请 100m 的内存，但实际只使用了 10m，那么它会增长 100m，而不是实际的使用量 RES：resident memory usage 常驻内存\n进程当前使用的内存大小，但不包括被换出到交换区的部分 包含其他进程的共享 如果申请 100m 的内存，实际使用 10m，它只增长 10m，与 VIRT 相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小 SHR：shared memory 共享内存\n除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR。（JVM 的内存使用量等于 RES-SHR） container_memory_working_set_bytes 与 Top RES 相等吗。\n为什么 container_memory_working_set_bytes 大于 top RES:\n因为 container_memory_working_set_bytes 包含 container_memory_cache，这涉及到 Linux 缓存机制，延伸阅读：https://zhuanlan.zhihu.com/p/449630026。遇到这种场景一般都是文件操作较多，可优先排除文件类操作。\n为什么 container_memory_working_set_bytes 小于 top RES:\n主要还是算法和数据来源不一样，top 的 RES=Code + Data，有些服务 Data 比较大。 当然实际测试会发现 RES!=Code + Data ，延伸阅读：https://liam.page/2020/07/17/memory-stat-in-TOP/\n另外可能看到的现象，top、granfana、docker stats、JMX 看到的使用量怎么都不一样，都是因为他们统计的维度不一样。\n所以通过 top 命令看到的数据不一定是真实的，container_memory_working_set_bytes 指标来自 cadvisor，cadvisor 数据来源 cgroup，可以查看以下文件获取真实的内存情况。\n# 老版本使用 cgroup v1 ll /sys/fs/cgroup/memory/ total 0 drwxr-xr-x. 2 root root 0 Dec 24 19:22 ./ dr-xr-xr-x. 13 root root 340 Dec 24 19:22 ../ -rw-r--r--. 1 root root 0 Dec 24 19:22 cgroup.clone_children --w--w--w-. 1 root root 0 Dec 24 19:22 cgroup.event_control -rw-r--r--. 1 root root 0 Dec 24 19:22 cgroup.procs -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.failcnt --w-------. 1 root root 0 Dec 24 19:22 memory.force_empty -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.slabinfo -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.max_usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.move_charge_at_immigrate -r--r--r--. 1 root root 0 Dec 24 19:22 memory.numa_stat -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.oom_control ----------. 1 root root 0 Dec 24 19:22 memory.pressure_level -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.soft_limit_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.stat -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.swappiness -r--r--r--. 1 root root 0 Dec 24 19:22 memory.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.use_hierarchy -rw-r--r--. 1 root root 0 Dec 24 19:22 notify_on_release -rw-r--r--. 1 root root 0 Dec 24 19:22 tasks # 新版本使用 cgroup v2 ll /sys/fs/cgroup/memory.* -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.current -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.events -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.events.local -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.high -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.low -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.max -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.min -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.numa_stat -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.oom.group -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.pressure -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.stat -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.current -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.events -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.high -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.max JVM 关于使用量和提交量的解释。\nUsed Size：The used space is the amount of memory that is currently occupied by Java objects. 当前实际真的用着的内存，每个 bit 都对应了有值的。\nCommitted Size：The committed size is the amount of memory guaranteed to be available for use by the Java virtual machine.\n操作系统向 JVM 保证可用的内存大小，或者说 JVM 向操作系统已经要的内存。站在操作系统的角度，就是已经分出去（占用）的内存，保证给 JVM 用了，其他进程不能用了。 由于操作系统的内存管理是惰性的，对于已申请的内存虽然会分配地址空间，但并不会直接占用物理内存，真正使用的时候才会映射到实际的物理内存，所以 committed \u0026gt; res 也是很可能的。\nJava 进程内存分析 Pod 的内存使用量 1.5G，都包含哪些。\nkernel memory 为 0，Cache 约 1100M，rss 约 650M，inactive_file 约 200M。可以看到 Cache 比较大，因为这个服务比较特殊有很多文件操作。\n# 这个数据和上面的 1.5G 不是同时的。 cat /sys/fs/cgroup/memory/memory.stat cache 1455861760 rss 685862912 rss_huge 337641472 mapped_file 504979456 swap 0 inactive_anon 805306368 active_anon 685817856 inactive_file 299671552 active_file 350883840 total_rss 685862912 total_rss_huge 337641472 total_mapped_file 504979456 total_inactive_file 299671552 total_active_file 350883840 # cgroup v2 变量变了 cat /sys/fs/cgroup/memory.stat anon 846118912 file 2321530880 kernel_stack 10895360 pagetables 15523840 percpu 0 sock 1212416 shmem 1933574144 file_mapped 1870290944 file_dirty 12288 file_writeback 0 swapcached 0 anon_thp 0 file_thp 0 shmem_thp 0 inactive_anon 2602876928 active_anon 176771072 inactive_file 188608512 active_file 199348224 unevictable 0 slab_reclaimable 11839688 slab_unreclaimable 7409400 slab 19249088 workingset_refault_anon 0 workingset_refault_file 318 workingset_activate_anon 0 workingset_activate_file 95 workingset_restore_anon 0 workingset_restore_file 0 workingset_nodereclaim 0 pgfault 2563565 pgmajfault 15 pgrefill 14672 pgscan 25468 pgsteal 25468 pgactivate 106436 pgdeactivate 14672 pglazyfree 0 pglazyfreed 0 thp_fault_alloc 0 thp_collapse_alloc 0 通过 Java 自带的 Native Memory Tracking 看下内存提交量。\n# Java 启动时先打开 NativeMemoryTracking，默认是关闭的。注意不要在生产环境长期开启，有性能损失 java -XX:NativeMemoryTracking=detail -jar # 查看详情 jcmd $(pgrep java) VM.native_memory detail scale=MB 通过 Native Memory Tracking 追踪到的详情大致如下，关注其中每一项 committed 值。\nNative Memory Tracking: (Omitting categories weighting less than 1MB) Total: reserved=68975MB, committed=1040MB - Java Heap (reserved=58944MB, committed=646MB) (mmap: reserved=58944MB, committed=646MB) - Class (reserved=1027MB, committed=15MB) (classes #19551) #加载类的个数 ( instance classes #18354, array classes #1197) (malloc=3MB #63653) (mmap: reserved=1024MB, committed=12MB) ( Metadata: ) ( reserved=96MB, committed=94MB) ( used=93MB) ( waste=0MB =0.40%) ( Class space:) ( reserved=1024MB, committed=12MB) ( used=11MB) ( waste=1MB =4.63%) - Thread (reserved=337MB, committed=37MB) (thread #335) #线程的个数 (stack: reserved=336MB, committed=36MB) (malloc=1MB #2018) - Code (reserved=248MB, committed=86MB) (malloc=6MB #24750) (mmap: reserved=242MB, committed=80MB) - GC (reserved=8243MB, committed=83MB) (malloc=19MB #45814) (mmap: reserved=8224MB, committed=64MB) - Compiler (reserved=3MB, committed=3MB) (malloc=3MB #2212) - Internal (reserved=7MB, committed=7MB) (malloc=7MB #31683) - Other (reserved=18MB, committed=18MB) (malloc=18MB #663) - Symbol (reserved=19MB, committed=19MB) (malloc=17MB #502325) (arena=2MB #1) - Native Memory Tracking (reserved=12MB, committed=12MB) (malloc=1MB #8073) (tracking overhead=11MB) - Shared class space (reserved=12MB, committed=12MB) (mmap: reserved=12MB, committed=12MB) - Module (reserved=1MB, committed=1MB) (malloc=1MB #4996) - Synchronization (reserved=1MB, committed=1MB) (malloc=1MB #2482) - Metaspace (reserved=97MB, committed=94MB) (malloc=1MB #662) (mmap: reserved=96MB, committed=94MB) - Object Monitors (reserved=8MB, committed=8MB) (malloc=8MB #39137) 一图解千愁，盗图。\nHeap Heap 是 Java 进程中使用量最大的一部分内存，是最常遇到内存问题的部分，Java 也提供了很多相关工具来排查堆内存泄露问题，这里不详细展开。Heap 与 RSS 相关的几个重要 JVM 参数如下： Xms：Java Heap 初始内存大小。（目前我们用的百分比控制，MaxRAMPercentage) Xmx：Java Heap 的最大大小。(InitialRAMPercentage) XX:+UseAdaptiveSizePolicy：是否开启自适应大小策略。开启后，JVM 将动态判断是否调整 Heap size，来降低系统负载。\nMetaspace Metaspace 主要包含方法的字节码，Class 对象，常量池。一般来说，记载的类越多，Metaspace 使用的内存越多。与 Metaspace 相关的 JVM 参数有： XX:MaxMetaspaceSize: 最大的 Metaspace 大小限制【默认无限制】 XX:MetaspaceSize=64M: 初始的 Metaspace 大小。如果 Metaspace 空间不足，将会触发 Full GC。 类空间占用评估，给两个数字可供参考：10K 个类约 90M，15K 个类约 100M。 什么时候回收：分配给一个类的空间，是归属于这个类的类加载器的，只有当这个类加载器卸载的时候，这个空间才会被释放。释放 Metaspace 的空间，并不意味着将这部分空间还给系统内存，这部分空间通常会被 JVM 保留下来。 扩展：参考资料中的Java Metaspace 详解，这里完美解释 Metaspace、Compressed Class Space 等。\nThread NMT 中显示的 Thread 部分内存与线程数与 -Xss 参数成正比，一般来说 committed 内存等于 Xss *线程数 。\nCode JIT 动态编译产生的 Code 占用的内存。这部分内存主要由-XX:ReservedCodeCacheSize 参数进行控制。\nInternal Internal 包含命令行解析器使用的内存、JVMTI、PerfData 以及 Unsafe 分配的内存等等。 需要注意的是，Unsafe_AllocateMemory 分配的内存在 JDK11 之前，在 NMT 中都属于 Internal，但是在 JDK11 之后被 NMT 归属到 Other 中。\nSymbol Symbol 为 JVM 中的符号表所使用的内存，HotSpot 中符号表主要有两种：SymbolTable 与 StringTable。 大家都知道 Java 的类在编译之后会生成 Constant pool 常量池，常量池中会有很多的字符串常量，HotSpot 出于节省内存的考虑，往往会将这些字符串常量作为一个 Symbol 对象存入一个 HashTable 的表结构中即 SymbolTable，如果该字符串可以在 SymbolTable 中 lookup（SymbolTable::lookup）到，那么就会重用该字符串，如果找不到才会创建新的 Symbol（SymbolTable::new_symbol）。 当然除了 SymbolTable，还有它的双胞胎兄弟 StringTable（StringTable 结构与 SymbolTable 基本是一致的，都是 HashTable 的结构），即我们常说的字符串常量池。平时做业务开发和 StringTable 打交道会更多一些，HotSpot 也是基于节省内存的考虑为我们提供了 StringTable，我们可以通过 String.intern 的方式将字符串放入 StringTable 中来重用字符串。\nNative Memory Tracking Native Memory Tracking 使用的内存就是 JVM 进程开启 NMT 功能后，NMT 功能自身所申请的内存。\n观察上面几个区域的分配，没有明显的异常。\nNMT 追踪到的 是 Committed，不一定是 Used，NMT 和 cadvisor 没有找到必然的对应的关系。可以参考 RSS，cadvisor 追踪到 RSS 是 650M，JVM Used 是 500M，还有大约 150M 浮动到哪里去了。\n因为 NMT 只能 Track JVM 自身的内存分配情况，比如：Heap 内存分配，direct byte buffer 等。无法追踪的情况主要包括：\n使用 JNI 调用的一些第三方 native code 申请的内存，比如使用 System.Loadlibrary 加载的一些库。 标准的 Java Class Library，典型的，如文件流等相关操作（如：Files.list、ZipInputStream 和 DirectoryStream 等）。主要涉及到的调用是 Unsafe.allocateMemory 和 java.util.zip.Inflater.init(Native Method)。 怎么追踪 NMT 追踪不到的其他内存，目前是安装了 jemalloc 内存分析工具，他能追踪底层内存的分配情况输出报告。\n通过 jemalloc 内存分析工具佐证了上面的结论，Unsafe.allocateMemory 和 java.util.zip.Inflater.init 占了 30%，基本吻合。\n启动 arthas 查看下类调用栈，在 arthas 里执行以下命令：\n# 先设置 unsafe true options unsafe true # 这个没有 stack sun.misc.Unsafe allocateMemory # 这个有 stack jdk.internal.misc.Unsafe allocateMemory stack java.util.zip.Inflater inflate 通过上面的命令，能看到 MongoDB 和 netty 一直在申请使用内存。注意：早期的 mongodb client 确实有无法释放内存的 bug，但是在我们场景，长期观察会发现内存申请了逐渐释放了，没有持续增长。回到开头的 ContainerOOM 问题，可能一个原因是流量突增，MongoDB 申请了更多的内存导致 OOM，而不是因为内存不释放。\nts=2022-12-29 21:20:01;thread_name=ForkJoinPool.commonPool-worker-1;id=22;is_daemon=true;priority=1;TCCL=jdk.internal.loader.ClassLoaders$AppClassLoader@1d44bcfa @jdk.internal.misc.Unsafe.allocateMemory() at java.nio.DirectByteBuffer.\u0026lt;init\u0026gt;(DirectByteBuffer.java:125) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:332) at sun.nio.ch.Util.getTemporaryDirectBuffer(Util.java:243) at sun.nio.ch.NioSocketImpl.tryWrite(NioSocketImpl.java:394) at sun.nio.ch.NioSocketImpl.implWrite(NioSocketImpl.java:413) at sun.nio.ch.NioSocketImpl.write(NioSocketImpl.java:440) at sun.nio.ch.NioSocketImpl$2.write(NioSocketImpl.java:826) at java.net.Socket$SocketOutputStream.write(Socket.java:1035) at com.mongodb.internal.connection.SocketStream.write(SocketStream.java:99) at com.mongodb.internal.connection.InternalStreamConnection.sendMessage(InternalStreamConnection.java:426) at com.mongodb.internal.connection.UsageTrackingInternalConnection.sendAndReceive(UsageTrackingInternalConnection.java:99) at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection.sendAndReceive(DefaultConnectionPool.java:444) ……………………………… at com.mongodb.MongoClientExt$1.execute(MongoClientExt.java:42) at com.facishare.oms.thirdpush.dao.MongoDao.save(MongoDao.java:31) ……………………………… 总结 Java 进程内存占用：Total=heap + non-heap + 上面说的这个其他。\njemalloc jemalloc 是一个比 glibc malloc 更高效的内存池技术，在 Facebook 公司被大量使用，在 FreeBSD 和 FireFox 项目中使用了 jemalloc 作为默认的内存管理器。使用 jemalloc 可以使程序的内存管理性能提升，减少内存碎片。\n比如 Redis 内存分配默认使用的 jemalloc，早期版本安装 redis 是需要手动安装 jemalloc 的，现在 redis 应该是在编译期内置好了。\n原来使用 jemalloc 是为了分析内存占用，通过 jemalloc 输出当前内存分配情况，或者通过 diff 分析前后内存差，大概能看出内存都分给睡了，占了多少，是否有内存无法释放的情况。\n后来参考了这个文章，把 glibc 换成 jemalloc 带来性能提升，降低内存使用，决定一试。\nhow we’ve reduced memory usage without changing any code：https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad\nDecreasing RAM Usage by 40% Using jemalloc with Python \u0026amp; Celery: https://zapier.com/engineering/celery-python-jemalloc/\n一个服务，运行一周，观察效果。\n使用 Jemalloc 之前： 使用 Jemalloc 之后（同时调低了 Pod 内存）： 注：以上结果未经生产长期检验。\n内存交还给操作系统 注意：下面的操作，生产环境不建议这么干。\n默认情况下，OpenJDK 不会主动向操作系统退还未用的内存（不严谨）。看第一张监控的图，会发现运行一段时间后，Pod 的内存使用量一直稳定在 80%\u0026ndash;90%不再波动。\n其实对于 Java 程序，浮动比较大的就是 heap 内存。其他区域 Code、Metaspace 基本稳定\n# 执行命令获取当前 heap 情况 jhsdb jmap --heap --pid $(pgrep java) #以下为输出 Attaching to process ID 7, please wait... Debugger attached successfully. Server compiler detected. JVM version is 17.0.5+8-LTS using thread-local object allocation. ZGC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 1287651328 (1228.0MB) NewSize = 1363144 (1.2999954223632812MB) MaxNewSize = 17592186044415 MB OldSize = 5452592 (5.1999969482421875MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 22020096 (21.0MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: ZHeap used 310M, capacity 710M, max capacity 1228M Java 内存不交还，几种情况：\nXms 大于实际需要的内存，比如我们服务设置了 Xms768M，但是实际上只需要 256，高峰期也就 512，到不了 Xms 的值也就无所谓归还。 上面 jmap 的结果，可以看到 Java 默认的配置 MaxHeapFreeRatio=70，这个 70% Free 几乎很难达到。（另外注意 Xmx==Xms 的情况下这两个参数无效，因为他怎么扩缩都不会突破 Xms 和 Xmx 的限制）\nMinHeapFreeRatio = 40 空闲堆空间的最小百分比，计算公式为：HeapFreeRatio =(CurrentFreeHeapSize/CurrentTotalHeapSize) * 100，值的区间为 0 到 100，默认值为 40。如果 HeapFreeRatio \u0026lt; MinHeapFreeRatio，则需要进行堆扩容，扩容的时机应该在每次垃圾回收之后。 MaxHeapFreeRatio = 70 空闲堆空间的最大百分比，计算公式为：HeapFreeRatio =(CurrentFreeHeapSize/CurrentTotalHeapSize) * 100，值的区间为 0 到 100，默认值为 70。如果 HeapFreeRatio \u0026gt; MaxHeapFreeRatio，则需要进行堆缩容，缩容的时机应该在每次垃圾回收之后。 对于 ZGC，默认是交还给操作系统的。可通过 -XX:+ZUncommit -XX:ZUncommitDelay=300 这两个参数控制（不再使用的内存最多延迟 300s 归还给 OS，线下环境可以改小点）。\n经过调整后的服务，内存提交在 500\u0026ndash;800M 之间浮动，不再是一条直线。\n问题原因分析和调整 回到开头问题，通过上面分析，2G 内存，RSS 其实占用 600M，为什么最终还是 ContainerOOM 了。\nkernel memory 为 0，排除 kernel 泄漏的原因。下面的参考资料里介绍了 kernel 泄露的两种场景。 Cache 很大，说明文件操作多。搜了一下代码，确实有很多 InputStream 调用没有显式关闭，而且有的 InputSteam Root 引用在 ThreadLocal 里，ThreadLocal 只 init 未 remove。 但是，ThreadLocal 的引用对象是线程池，池不回收，所以这部分可能会无法关闭，但是不会递增，但是 cache 也不能回收。 优化办法：ThreadLocal 中对象是线程安全的，无数据传递，直接干掉 ThreadLocal；显式关闭 InputStream。运行一周发现 cache 大约比优化前低 200\u0026ndash;500M。 ThreadLocal 引起内存泄露是 Java 中很经典的一个场景，一定要特别注意。 一般场景下，Java 程序都是堆内存占用高，但是这个服务堆内存其实在 200-500M 之间浮动，我们给他分了 768M，从来没有到过这个值，所以调低 Xms。留出更多内存给 JNI 使用。 线下环境内存分配切换到 jemalloc，长期观察大部分效果可以，但是对部分应用基本没有效果。 经过上述调整以后，线下环境 Pod 内存使用量由 1G 降到 600M 作用。线上环境内存使用量在 50%\u0026ndash;80%之间根据流量大小浮动，原来是 85% 居高不小。\n参考资料 Java 进程内存分布：https://cloud.tencent.com/developer/article/1666640\nJava Metaspace 详解：https://www.javadoop.com/post/metaspace\nhow we’ve reduced memory usage without changing any code：https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad\nSpring Boot 引起的堆外内存泄漏排查及经验总结：https://tech.meituan.com/2019/01/03/spring-boot-native-memory-leak.html\nPod 进程内存缓存分析：https://zhuanlan.zhihu.com/p/449630026\nLinux 内存中的 Cache 真的能被回收么：https://cloud.tencent.com/developer/article/1115557\nLinux kernel memory 导致的 POD OOM killed: https://www.cnblogs.com/yannwang/p/13287963.html\ncgroup 内存泄露问题：https://www.cnblogs.com/leffss/p/15019898.html\n","date":"2023-01-07","id":9,"permalink":"/blog/java-memory/","summary":"故事背景：\n一个 K8S Pod，里面只有一个 Java 进程，K8S request 和 limit memory 都是 2G，Java 进程核心参数包括：-XX:+UseZGC -Xmx1024m -Xms768m -XX:SoftMaxHeapSize=512m。\n服务启动一段时间后，查看 Grafana 监控数据，Pod 内存使用量约 1.5G，JVM 内存使用量约 500M，通过 jvm dump 分析没有任何大对象，运行三五天后出现 ContainerOOM。\n首先区分下 ContainerOOM 和 JvmOOM，ContainerOOM 是 Pod 内存不够，Java 向操作系统申请内存时内存不足导致。\n问题来了：\nPod 2G 内存，JVM 设置了 Xmx 1G，已经预留了 1G 内存，为什么还会 ContainerOOM，这预留的 1G 内存被谁吃了。 正常情况下（无 ContainerOOM），Grafana 看到的监控数据，Pod 内存使用量 1.5G， JVM 内存使用量 500M，差别为什么这么大。 Grafana 看到的监控数据，内存使用量、提交量各是什么意思，这些值是怎么算出来的，和 Pod 进程中如何对应，为什么提交量一直居高不小。 Grafana 监控图。\n统计指标 Pod 内存使用量统计的指标是 container_memory_working_set_bytes：\ncontainer_memory_usage_bytes = container_memory_rss + container_memory_cache + kernel memory container_memory_working_set_bytes = container_memory_usage_bytes - total_inactive_file（未激活的匿名缓存页） container_memory_working_set_bytes 是容器真实使用的内存量，也是资源限制 limit 时的 OOM 判断依据。","tags":["k8s","Java"],"title":"K8S 容器内 Java 进程内存分析"},{"content":"为 VS Code Web 版 code-server 增加外部认证，并支持多用户，不同用户的 code-server 实例完全隔离。\n主要为了解决问题：\ncode-server 本身只支持配置文件形式的用户名密码认证（截止目前，以后也许会改进）。所以引入了外部认证系统，Google、GitHub、 okta、CAS、Keycloak 等理论上都是支持的。\ncode-server 默认没有数据隔离，所以又加了一层 auth proxy，为每个用户创建一个（或多个）code-server 实例，通过 proxy 代理到各自的实例，以实现用户间的数据隔离。\n使用开源 Auth Proxy，无需自己编码即可实现认证授权流程，比如 code flow with pkce 对大部分人来说读懂这个协议都很困难。\n此文档源码请参考：architecture-diagram\n使用组件 keycloak\nRedhat 开源 IAM 系统，目前也是 CNCF 项目，提供用户、组织服务，提供标准 OIDC。\noauth2-proxy\n认证代理，配合 keycloak 提供完整 OAuth2 Code Flow 认证流程。也可以试试 pomerium，看样子也不错。\n架构图如下。\n核心逻辑 架构图简单解读，所有过程官方文档都有详细说明，都是配置，以官方配置为准。\nkeycloak 创建 client，使用 OIDC 协议，作为 oauth2-proxy 的 provider。\ningress(nginx) 使用 auth_request 指令拦截所有请求，从 oauth2-proxy 进行代理认证，配置可参考 oauth2-proxy auth_request 指导。\nnginx.ingress.kubernetes.io/auth-signin: https://$host/oauth2/start?rd=$escaped_request_uri nginx.ingress.kubernetes.io/auth-url: https://$host/oauth2/auth 认证通过后，将用户名/ID 作为标识，通过 Http Header （举例如 X-Forwarded-Preferred-Username) 传入 upstream。\ngateway(nginx) 从 Header 中获取用户标识，代理到此用户对应的 code-server 实例。\nlocation / { …… proxy_pass http://code-server-$http_x_forwarded_for_preferred_username; } code-server 各个实例部署时，以免认证方式部署。\n每个 code-server 实例挂载不同的存储，实现完全隔离。\n","date":"2022-09-07","id":10,"permalink":"/blog/code-server/","summary":"为 VS Code Web 版 code-server 增加外部认证，并支持多用户，不同用户的 code-server 实例完全隔离。\n主要为了解决问题：\ncode-server 本身只支持配置文件形式的用户名密码认证（截止目前，以后也许会改进）。所以引入了外部认证系统，Google、GitHub、 okta、CAS、Keycloak 等理论上都是支持的。\ncode-server 默认没有数据隔离，所以又加了一层 auth proxy，为每个用户创建一个（或多个）code-server 实例，通过 proxy 代理到各自的实例，以实现用户间的数据隔离。\n使用开源 Auth Proxy，无需自己编码即可实现认证授权流程，比如 code flow with pkce 对大部分人来说读懂这个协议都很困难。\n此文档源码请参考：architecture-diagram\n使用组件 keycloak\nRedhat 开源 IAM 系统，目前也是 CNCF 项目，提供用户、组织服务，提供标准 OIDC。\noauth2-proxy\n认证代理，配合 keycloak 提供完整 OAuth2 Code Flow 认证流程。也可以试试 pomerium，看样子也不错。\n架构图如下。\n核心逻辑 架构图简单解读，所有过程官方文档都有详细说明，都是配置，以官方配置为准。\nkeycloak 创建 client，使用 OIDC 协议，作为 oauth2-proxy 的 provider。\ningress(nginx) 使用 auth_request 指令拦截所有请求，从 oauth2-proxy 进行代理认证，配置可参考 oauth2-proxy auth_request 指导。\nnginx.ingress.kubernetes.io/auth-signin: https://$host/oauth2/start?rd=$escaped_request_uri nginx.","tags":["devops"],"title":"使用 Visual Studio Code 搭建多用户远程 IDE"},{"content":"基于 Envoy + Java Agent 的智能路由服务实现方案介绍。\n核心需求 服务自动注册和发现，通过 Service Name 直接调用服务。当然基本的负载均衡策略、熔断降级限流等功能也要支持。 公司约定的路由策略，支持按照租户路由到特定环境的服务，比如 VIP、Gray、Sandbox 等。 多集群通信，同云内新老 K8S 集群路由打通，可通过 POD IP 互相通信。 跨云通信，支持通过 VPN 或代理，从专属云访问公有云服务。 整体架构 智能路由服务从逻辑上分为数据平面和控制平面，主要包含以下组件。\nNacos：服务注册中心，配置中心。 XDS Server：对接服务注册中心、配置中心，实现 CDS、LDS、RDS 协议将集群、服务、路由、灰度租户等配置下发到 Envoy。 Envoy + WASM Plugin：通过 Envoy 代理流量，自定义 WASM 插件实现按照租户、用户路由到不同服务，实现自定义负载均衡策略。 Java Agent：增强 Java 应用 Http Client，拦截 OkHttp、Apache Http Client、RestTemplate、OpenFeign 等客户端调用，将流量重定向到 Envoy，Envoy 再根据服务名路由到真实的 Pod，实现服务发现和灾备切换。 Nacos Service CRD：自定义 Nacos Service CRD，将 Service 注册到 Nacos 中作为一个永久实例，解决跨云、跨集群服务调用。比如跨云情况下注册的是一个公网地址或 VPN 可通的地址。 C4Context title 基于 Envoy + Java Agent 的智能路由服务 Enterprise_Boundary(dp, \"Data Plane\") { Container(appA, \"Application A\", \"Java,Agent\", \"Agent 拦截客户端重定向到 Envoy\") Container(envoy, \"Envoy Proxy\", \"Envoy,WASM\", \"代理所有入口流量\n基于租户、服务负载均衡\") Container(appB, \"Application B\", \"Java,Agent\", \"应用注册到服务中心\") Rel(appA, envoy, \"request by name\", \"http\") Rel(envoy, appB, \"http proxy \u0026 lb\", \"http\") UpdateRelStyle(appA, envoy, $offsetX=\"-40\",$offsetY=\"-40\") UpdateRelStyle(envoy, appB, $offsetX=\"-40\",$offsetY=\"-40\") } Enterprise_Boundary(cp, \"Control Plane\") { System(registry, \"服务注册\", \"服务注册，服务元数据\n配置管理，双向刷新\") Container(xdsServer, \"控制面板\", \"Java,Grpc\", \"对接服务注册中心配置中心\n实现 XDS 协议将配置下发到 Envoy\") System(config, \"配置管理\", \"服务注册，服务元数据\n配置管理，双向刷新\") Rel_L(xdsServer, registry, \"实时获取服务实例\") Rel_R(xdsServer, config, \"实时配置刷新\") UpdateRelStyle(xdsServer, registry, $offsetX=\"-40\",$offsetY=\"-20\") UpdateRelStyle(xdsServer, config, $offsetX=\"-40\",$offsetY=\"-20\") } Rel_U(xdsServer,envoy,\"通过 XDS 实现配置动态下发\",\"grpc\") Rel_D(appA, registry, \"服务注册，配置刷新\") Rel_D(appB, config, \"服务注册，配置刷新\") UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\") 方案对比 此方案原始的目标有几个：\n语言无关，可以不绑定 Java。目前看来这是个伪需求。 实现类似 Istio Ambient Mesh，剔除 Egress 流量代理，每个 Node 部署一个 Envoy Proxy，减少 Sidecar 资源开销。目前随着 Istio Ambient Mesh 成熟，这个优点反而也没有了。 对比 K8S 体系、Spring Cloud 体系，此方案优点：\n各服务实际上只需要注入服务中心，服务发现和负载均衡交给 Agent 和 Envoy，对于老的 Spring 项目也能直接使用，相对 Spring Cloud 轻量一些。 不需要引入 Istio 也能支持跨云、跨集群访问场景，Istio 相对还是比较重。 此方案缺点：\n本质上还是 Proxy 模式，Proxy 的所有缺点他都绕不过，比如：性能损耗、Http Keepalive 和 reset 响应。 对服务和配置实时刷新，要比 K8S、Spring Cloud 略微延迟，对高并发场景难免有中断。 单点故障影响范围太大，以及 Proxy 任何配置性错误都是致命的。 综上，随着 Istio Ambient Mesh 以及基于 eBPF 的 Cilium Mesh 的成熟，这个方案可能逐渐退出历史舞台。那么，使用 Spring Cloud 全家桶快速启动先让业务用起来，反而成了一个最简单的方案。\n功能实现方案 主要功能实现方式如下。\n服务注册 服务通过 nacos support 或 nacos starter 注册到服务中心，关注下 Nacos 数据模型：\nnamespace - group - service - cluster - instance: ip,port,metadata namespace 和 group 的设计目的是为了实现隔离。\n同 service 下 instance 唯一标记：ip + port + cluster。metadata 不作为唯一性标记。 同 namespace 不同 group 下 service 可以完全相同。 Nacos 模型 开源原生默认值 我们方案 namespace 租户/环境 ，默认 public 固定自定义值 group 组织/虚拟分组，默认 DEFAULT 默认 DEFAULT，如果某个组确认自己的服务不给组用可自定义 group service spring.application.name 默认也是 spring.application.name，子模块名 cluster 虚拟，a k8s cluster/ a AZ 线上发布系统的“环境”英文名，实际是 k8s 的 namespace instance 一个 Java 应用，一个 jar 或一个 war 服务 一个 jar 或一个 war 服务 注册实例信息约束：\nserviceName: appName.modeleName 应用的子模块名，目前的字符和长度限制都能满足要求 clusterName: 发布系统定义的“环境”英文名 ip: pod ip port: container port enabled： true or false 用于主动控制上下线，下线保留实例不承载流量 weight：权重 metadata： - contextPath： 推荐等同子模块名，要求必须有且不能随意变更，可以是根目录 - preserved.register.source: 官方自动加，如 Spring Cloud、Dubbo。 - secure：官方开源客户端自动加 boolean 值，标记 http or https 协议 - protocol：通信协议，http/grpc/dubbo - version：版本标记，后续扩展路由策略支持多版本或限定版本。 - runtime：k8s info、node info。 对于专属云访问公有云，目前是通过 VPN 代理方式，那么在专属云访问公有云时，如何通过 Service 名字映射到公有云服务呢。 我们会在专属云内，手动（优化为自定义 K8S CRD，联动 GitOps 自动部署）在 Nacos 中增加一个永久性实例（关于永久性实例和临时实例的说明请参考官方文档），只是这个实例的 IP 不是 POD IP，是通过 VPN 可通的 IP。\n服务发现 调用方可使用 OkHttp、RestTemplate、OpenFeign 等客户端，直接使用服务名调用，比如：GET http://user-service/users。\n服务发现和负载均衡策略，其实依赖三个组件：XDS Server、Envoy + WASM、Java Agent。\n基本实现步骤：\nXDS Server 从 Nacos 实时获取最新的服务和实例列表，从配置中心获取服务灰度列表，通过 ADS 协议实时下发到 Envoy。 我们为 Envoy 定制了一个 WASM Plugin，这个 Plugin 支持通过租户路由到 Gray、VIP、Sandbox 等不同环境，Envoy 通过环境标记负载到真实的 POD 上。 Java Agent 增强 OkHttp 增加自定义 intercept，拦截服务名重定向到 Envoy，Envoy 根据服务名、路径、Header 路由到真实的后端服务。 我们的 RestTemplate、OpenFeign 客户端做了定制，底层连接器都切换到了 OkHttp。 客户端调用时，Header 中增加租户信息。 客户端调用时不需要关心服务的 contextPath，Envoy 会自动追加 contextPath。 路由和负载均衡规则 运行环境定义： Gray: foneshare-gray 用于常规发布的灰度过程；承载 QA 专用在线测试租户 Stage: foneshare-stage 用于大版本发布的灰度过程，承载 QA 专用在线测试租户、必要的真实租户 Urgent: foneshare-urgent 用于解决线上 vip、svip 面临的紧急 bug, 承载 bug 相关的 vip、svip 租户 Normal: foneshare、foneshare01、foneshare02、foneshare03、foneshare04 承载 vip 之外的租户 VIP: foneshare-vip 承载 vip 的租户 SVIP: 一个 foneshare-svip 承载多个 svip 租户 SSVIP: 一个环境承担一个租户，如 foneshare-yqsl 承载 ssvip 租户 Sandbox：所有以 _sandbox 结尾的租户都会路由到 Sandbox 环境。\n环境路由优先级从高到低：\nSSVIP \u0026gt; Gray \u0026gt; Urgent \u0026gt; Stage \u0026gt; SVIP \u0026gt; VIP \u0026gt; Sandbox \u0026gt; Normal\n对于同一租户，既配置在 vip 的灰度名单，同时又配置到 gray 的灰度名单，实际路由时走哪个环境：\nP1，最高优先级，gray、urgent、yqsl 等专属环境，tenantId 匹配任意环境就会返回； P2，第 2 优先级，stage； P3，第 3 优先级，svip； P4，第 4 优先级，vip； P5，第 5 优先级，sandbox； P6，默认 normal，上述环境均未匹配到后，路由到 normal 环境。\n按照上述顺序的原则，如一家租户既配置在 vip 同时又配置在 gray，实际会路由到 gray 环境。 注意：\n这里路由到 gray是指 gray 中存在对应的服务，如果 gray 中不存在服务，会按匹配到的优先级（vip）继续找，直到找到可用的服务。 命中条件：租户在这个环境的这个服务名单里（租户+服务唯一确定）。 沙箱用户比较特殊，是 EA 以 _sandbox 结尾。 Envoy 配置下发和更新 Envoy 通过文件系统或查询管理服务器发现其各种动态资源。这些发现服务及其相应的 API 统称为 xDS。\n我们的控制面 XDS Server 只实现了聚合发现服务（ADS），通过 ADS 使用单个流推送 CDS、EDS 和 RDS 资源，实现无中断的更新。\nXDS Server 缓存了各个 Envoy 的 grpc connection，同时响应 Nacos 和配置中心的更新事件，收到更新后再通过 grpc 推送到各个 Envoy 终端。\n使用限制 请求 Header 必须要包含 x-fs-ea 或 x-fs-ei 参数（推荐 x-fs-ea），否则无法支持按租户路由。 同一个服务在同一个环境，发布流程中的 contextPath 必须一致，因为是按环境类型统一路由只能有一个 contextPath。 配置文件变更需要 30s 后才能生效，这取决了 CMS 配置系统拉取方式。 新增加服务无法立即感知到（是新的服务，不是服务实例，实例能即时感知），我们是 10 分钟扫描一次服务，判断有无服务变更。 Nacos 服务端部署 部署形态：\n公有云一套，承接公有云新老集群。 每个专属云有独立的一套。 注意事项：\nNacos 需要放开 http（8848）和 grcp（9848、9849）端口。 认证：使用用户名密码模式。不同组创建独立的用户名密码，单独授权。默认的用户nacos不要用且权限不足。 连接时配置的 namespace 实际是 namespace id，可以考虑创建 namespace 时主动设置 namespace id 等同于 namespace name，便于定位，误删或迁移的时候能保证 ID 不变。 ","date":"2023-08-07","id":11,"permalink":"/docs/cloud/service-mesh-envoy/","summary":"基于 Envoy + Java Agent 的智能路由服务实现方案介绍。\n核心需求 服务自动注册和发现，通过 Service Name 直接调用服务。当然基本的负载均衡策略、熔断降级限流等功能也要支持。 公司约定的路由策略，支持按照租户路由到特定环境的服务，比如 VIP、Gray、Sandbox 等。 多集群通信，同云内新老 K8S 集群路由打通，可通过 POD IP 互相通信。 跨云通信，支持通过 VPN 或代理，从专属云访问公有云服务。 整体架构 智能路由服务从逻辑上分为数据平面和控制平面，主要包含以下组件。\nNacos：服务注册中心，配置中心。 XDS Server：对接服务注册中心、配置中心，实现 CDS、LDS、RDS 协议将集群、服务、路由、灰度租户等配置下发到 Envoy。 Envoy + WASM Plugin：通过 Envoy 代理流量，自定义 WASM 插件实现按照租户、用户路由到不同服务，实现自定义负载均衡策略。 Java Agent：增强 Java 应用 Http Client，拦截 OkHttp、Apache Http Client、RestTemplate、OpenFeign 等客户端调用，将流量重定向到 Envoy，Envoy 再根据服务名路由到真实的 Pod，实现服务发现和灾备切换。 Nacos Service CRD：自定义 Nacos Service CRD，将 Service 注册到 Nacos 中作为一个永久实例，解决跨云、跨集群服务调用。比如跨云情况下注册的是一个公网地址或 VPN 可通的地址。 C4Context title 基于 Envoy + Java Agent 的智能路由服务 Enterprise_Boundary(dp, \"","tags":["Spring Boot","Java","Envoy"],"title":"基于 Envoy 的智能路由服务"},{"content":"我们整个系统应用内存占用目前约 1000GB，未来目标是能够降低到 500GB 内，为了这个目标，我们正在做的努力。\n","date":"2023-12-10","id":12,"permalink":"/docs/guides/from-1024-to-512/","summary":"我们整个系统应用内存占用目前约 1000GB，未来目标是能够降低到 500GB 内，为了这个目标，我们正在做的努力。","tags":[],"title":"从 1024 到 512"},{"content":"","date":"2023-09-07","id":13,"permalink":"/docs/","summary":"","tags":[],"title":"Docs"},{"content":"","date":"2023-11-26","id":14,"permalink":"/contributors/","summary":"","tags":[],"title":"Contributors"},{"content":"","date":"2023-11-26","id":15,"permalink":"/tags/java/","summary":"","tags":[],"title":"Java"},{"content":"","date":"2023-11-26","id":16,"permalink":"/contributors/l10178/","summary":"","tags":[],"title":"l10178"},{"content":"","date":"2023-11-26","id":17,"permalink":"/tags/","summary":"","tags":[],"title":"Tags"},{"content":"","date":"2023-09-07","id":18,"permalink":"/privacy/","summary":"","tags":[],"title":"Privacy Policy"},{"content":"","date":"2023-09-07","id":19,"permalink":"/","summary":"","tags":[],"title":"卫星实验室"},{"content":"","date":"2023-09-07","id":20,"permalink":"/categories/","summary":"","tags":[],"title":"Categories"},{"content":"","date":"2023-09-07","id":21,"permalink":"/tags/k8s/","summary":"","tags":[],"title":"k8s"},{"content":"","date":"2023-09-07","id":22,"permalink":"/categories/k8s/","summary":"","tags":[],"title":"k8s"},{"content":"","date":"2023-08-07","id":23,"permalink":"/tags/envoy/","summary":"","tags":[],"title":"Envoy"},{"content":"","date":"2023-08-07","id":24,"permalink":"/categories/java/","summary":"","tags":[],"title":"Java"},{"content":"","date":"2023-08-07","id":25,"permalink":"/tags/spring-boot/","summary":"","tags":[],"title":"Spring Boot"},{"content":"","date":"2023-08-07","id":26,"permalink":"/categories/spring-boot/","summary":"","tags":[],"title":"Spring Boot"},{"content":"","date":"2022-09-07","id":27,"permalink":"/tags/devops/","summary":"","tags":[],"title":"devops"}]