<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>卫星实验室 on XLabs</title><link>https://www.xlabs.club/</link><description>Recent content in 卫星实验室 on XLabs</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>Copyright (c) 2020-2023 XLabs Club</copyright><lastBuildDate>Thu, 07 Sep 2023 16:33:54 +0200</lastBuildDate><atom:link href="https://www.xlabs.club/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction</title><link>https://www.xlabs.club/docs/cloud/introduction/</link><pubDate>Thu, 07 Sep 2023 16:04:48 +0200</pubDate><guid>https://www.xlabs.club/docs/cloud/introduction/</guid><description>云原生技术探索。</description></item><item><title>Introduction</title><link>https://www.xlabs.club/docs/guides/introduction/</link><pubDate>Thu, 07 Sep 2023 16:04:48 +0200</pubDate><guid>https://www.xlabs.club/docs/guides/introduction/</guid><description>卫星实验室，一个专注于研究卫星以及 CRM 的开源组织。
此项目为卫星实验室主页 xlabs.club 的源码，记录常用文档和零碎博客，欢迎提交 PR 开源共建。
本地开发 本项目使用 Hugo 开发，使用 Doks 作为 Hugo 主题。
本地开发时先安装 Nodejs，然后使用 pnpm（或 npm） 安装 Hugo bin，本地不需要提前安装 Hugo。
# 安装 npm 依赖包，注意网络连接 pnpm install # 启动 Web，然后浏览器访问 http://localhost:1313/即可浏览效果 pnpm run dev # 代码提交前先检查 pnpm run lint # 编译结果 pnpm run build # 创建新页面 pnpm run create docs/guides/faq.md pnpm run create blog/k8s.md License 本文档采用 CC BY-NC 4.0 许可协议。</description></item><item><title>TL;DR</title><link>https://www.xlabs.club/docs/guides/tldr/</link><pubDate>Thu, 07 Sep 2023 16:04:48 +0200</pubDate><guid>https://www.xlabs.club/docs/guides/tldr/</guid><description>常用 Kubernetes 命令，复制，粘贴，这就是生活。
复制 secret 到另一个 namespace。 kubectl get secret mys --namespace=na -oyaml | grep -v &amp;#39;^\s*namespace:\s&amp;#39; | kubectl apply --namespace=nb -f - 批量删除 pod。 kubectl get pods --all-namespaces | grep Evicted | awk &amp;#39;{print $2 &amp;#34; --namespace=&amp;#34; $1}&amp;#39; | xargs kubectl delete pod # Delete by label kubectl delete pod -n idaas-book -l app.kubernetes.io/name=idaas-book 密钥解密。 kubectl get secret my-creds -n mysql -o jsonpath=&amp;#34;{.data.ADMIN_PASSWORD}&amp;#34; | base64 --decode 合并多个 kube config 文件。 export KUBECONFIG=~/.</description></item><item><title>总体架构</title><link>https://www.xlabs.club/docs/platform/introduction/</link><pubDate>Thu, 07 Sep 2023 16:04:48 +0200</pubDate><guid>https://www.xlabs.club/docs/platform/introduction/</guid><description>我们的平台工程总体架构</description></item><item><title>统一身份认证</title><link>https://www.xlabs.club/docs/platform/iam/</link><pubDate>Tue, 19 Dec 2023 22:26:42 +0800</pubDate><guid>https://www.xlabs.club/docs/platform/iam/</guid><description>统一身份认证（Identity and Access Management，身份认证和访问控制，简称 IAM）的技术选型和实践。
核心需求 集中管理：从一个地方管理账户和身份。 单点登录：允许用户使用一组凭据访问所有集成的系统和应用，避免记忆多个用户名和密码。 动态访问控制：基于角色和策略动态授予或撤销访问权限。 审计与合规：记录和监控访问活动，以支持合规性审计。 无缝快速集成：作为平台工程的一部分更强调“自助”，各个应用能够无缝快速接入。 强化认证机制：采用多因素认证（MFA）等方法，确保只有授权用户才能访问系统和数据。 技术选项 为满足以上需求，在初期技术选项时主要关注以下几个开源组件。
keycloak: 全面的 IAM 解决方案 ，实现用户、权限管理，单点登录、MFA 等。 Dex: 身份代理，连接多个身份源，仅作为 OpenID Connect。 Ory: 包含多个独立的组件，组成一个全家桶的解决方案。 oauth2-proxy: 反向代理工具，专为提供 OAuth 2.0 身份验证和授权服务而设计，附带基于用户、分组、角色的权限管理。 Pomerium: Pomerium 不仅仅是一个 OAuth 2.0 代理，它还提供了细粒度的访问控制，能够根据用户、组、和其他上下文属性来决定访问权限。 以下为 keycloak 和 Dex 的简单对比。为什么不把 Ory 加进来，因为没有实际用过，不便于发表意见，如果你是一个 Ory 用户欢迎补充。
特性/工具 Keycloak Dex 类型 全面的 IAM 解决方案 身份代理 用户管理 支持内置用户管理 不直接管理用户，依赖外部身份提供者 协议支持 OpenID Connect、OAuth 2.0、SAML 2.0 OpenID Connect SSO 支持 依赖外部身份提供者实现 社交登录 支持多种社交登录选项 不直接支持，可通过连接外部身份提供者实现 角色管理 支持复杂的角色和权限管理 不直接支持 扩展性 高，适合各种规模和复杂性的需求 适合将多个身份源统一到一个认证流程的环境 使用场景 需要全面、集中式身份管理的组织 需要统一多个身份源认证，如在云原生环境中 用户界面 提供丰富的用户和管理员界面 主要是 API，没有详细的用户界面 适用性 适用于需要完整 IAM 解决方案的组织 适用于作为多个身份源代理，尤其在 Kubernetes 环境中 以下为 OAuth2 Proxy 和 Pomerium 的简单对比。</description></item><item><title>重复 Transfer-Encoding Header 引起的服务 500 问题</title><link>https://www.xlabs.club/blog/duplicate-transfer-encoding-chunked/</link><pubDate>Sun, 26 Nov 2023 10:21:44 +0800</pubDate><guid>https://www.xlabs.club/blog/duplicate-transfer-encoding-chunked/</guid><description>我有一个 Spring Boot 应用服务，提供了一些简单的查询接口，本身运行很正常，通过 curl 或其他 http 客户端 localhost 请求都没有问题。
某天通过 Traefik 代理了此服务，经过代理后再访问，某个接口一直都是 500 internal server error，其他接口都没有问题。通过 tcpdump 抓包发现，应用服务并没有返回任何 500 错误，而且 Traefik 本身也没有错误日志。
根据网上经验排查了 Traefik SSL 证书问题、路径问题、消息体太大问题、请求 Header 不合规问题，都一一否定。最后无意间看了一眼 Response Header，发现 Spring Boot 应用返回了两个 Transfer-Encoding: chunked Header。
再根据此 Header 搜索，发现果然有人遇到过类似问题，请参考这几个链接。
https://github.com/traefik/traefik/issues/7741 https://github.com/spring-projects/spring-framework/issues/21523 https://github.com/spring-projects/spring-boot/issues/37646 https://stackoverflow.com/questions/77042701/nginx-upstream-sent-duplicate-header-line-transfer-encoding-chunked-previo 从上面链接描述中可知，不仅 Traefik 会出现此问题，nginx 包含以 nginx 为基础的 ingress 也会出现同样问题，不过 nginx 返回错误码是 502。
我所使用的 Traefik(2.10.x) 和 Spring Boot(2.7.x) 都是当前日期最新版本，目前仍然有问题。
出现此问题的代码类似如下。
import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.</description></item><item><title>K8S 容器 PID 限制引起的 OOM</title><link>https://www.xlabs.club/blog/k8s-pid-limiting-oom/</link><pubDate>Thu, 07 Sep 2023 16:21:44 +0800</pubDate><guid>https://www.xlabs.club/blog/k8s-pid-limiting-oom/</guid><description>问题描述：
一个 Java 应用跑在 K8S 容器内，Pod 内只有 Java 这一个进程。应用跑了一段时间后，CPU、内存占用都不高，但是却出现以下 OutOfMemoryError 错误。
Exception in thread &amp;#34;slow-fetch-15&amp;#34; java.lang.OutOfMemoryError: unable to create new native thread 428 at java.lang.Thread.start0(Native Method) 429 at java.lang.Thread.start(Thread.java:719) 430 at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957) 431 at java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1025) 432 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167) 433 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 进入 Pod 内，尝试执行任何操作，又会出现 unable to start container process 错误。
一开始怀疑是内存不足，调大了内存，同时也缩小了 Java 的 xss， 都不起作用。
真实原因： K8S 容器限制了 PID 数，无法创建新的线程，在 Pod 内 cat /sys/fs/cgroup/pids/pids.max 发现是 1024。
关于 K8S pid limit， 可参考此资料：https://kubernetes.</description></item><item><title>K8S 容器内 Java 进程内存分析</title><link>https://www.xlabs.club/blog/java-memory/</link><pubDate>Sat, 07 Jan 2023 10:54:37 +0800</pubDate><guid>https://www.xlabs.club/blog/java-memory/</guid><description>故事背景：
一个 K8S Pod，里面只有一个 Java 进程，K8S request 和 limit memory 都是 2G，Java 进程核心参数包括：-XX:+UseZGC -Xmx1024m -Xms768m -XX:SoftMaxHeapSize=512m。
服务启动一段时间后，查看 Grafana 监控数据，Pod 内存使用量约 1.5G，JVM 内存使用量约 500M，通过 jvm dump 分析没有任何大对象，运行三五天后出现 ContainerOOM。
首先区分下 ContainerOOM 和 JvmOOM，ContainerOOM 是 Pod 内存不够，Java 向操作系统申请内存时内存不足导致。
问题来了：
Pod 2G 内存，JVM 设置了 Xmx 1G，已经预留了 1G 内存，为什么还会 ContainerOOM，这预留的 1G 内存被谁吃了。 正常情况下（无 ContainerOOM），Grafana 看到的监控数据，Pod 内存使用量 1.5G， JVM 内存使用量 500M，差别为什么这么大。 Grafana 看到的监控数据，内存使用量、提交量各是什么意思，这些值是怎么算出来的，和 Pod 进程中如何对应，为什么提交量一直居高不小。 Grafana 监控图。
统计指标 Pod 内存使用量统计的指标是 container_memory_working_set_bytes：
container_memory_usage_bytes = container_memory_rss + container_memory_cache + kernel memory container_memory_working_set_bytes = container_memory_usage_bytes - total_inactive_file（未激活的匿名缓存页） container_memory_working_set_bytes 是容器真实使用的内存量，也是资源限制 limit 时的 OOM 判断依据。</description></item><item><title>使用 Visual Studio Code 搭建多用户远程 IDE</title><link>https://www.xlabs.club/blog/code-server/</link><pubDate>Wed, 07 Sep 2022 16:21:44 +0800</pubDate><guid>https://www.xlabs.club/blog/code-server/</guid><description>为 VS Code Web 版 code-server 增加外部认证，并支持多用户，不同用户的 code-server 实例完全隔离。
主要为了解决问题：
code-server 本身只支持配置文件形式的用户名密码认证（截止目前，以后也许会改进）。所以引入了外部认证系统，Google、GitHub、 okta、CAS、Keycloak 等理论上都是支持的。
code-server 默认没有数据隔离，所以又加了一层 auth proxy，为每个用户创建一个（或多个）code-server 实例，通过 proxy 代理到各自的实例，以实现用户间的数据隔离。
使用开源 Auth Proxy，无需自己编码即可实现认证授权流程，比如 code flow with pkce 对大部分人来说读懂这个协议都很困难。
此文档源码请参考：architecture-diagram
使用组件 keycloak
Redhat 开源 IAM 系统，目前也是 CNCF 项目，提供用户、组织服务，提供标准 OIDC。
oauth2-proxy
认证代理，配合 keycloak 提供完整 OAuth2 Code Flow 认证流程。也可以试试 pomerium，看样子也不错。
架构图如下。
核心逻辑 架构图简单解读，所有过程官方文档都有详细说明，都是配置，以官方配置为准。
keycloak 创建 client，使用 OIDC 协议，作为 oauth2-proxy 的 provider。
ingress(nginx) 使用 auth_request 指令拦截所有请求，从 oauth2-proxy 进行代理认证，配置可参考 oauth2-proxy auth_request 指导。
nginx.ingress.kubernetes.io/auth-signin: https://$host/oauth2/start?rd=$escaped_request_uri nginx.</description></item><item><title>从 Spring 到 Spring Boot</title><link>https://www.xlabs.club/docs/java/migrating-spring-to-spring-boot/</link><pubDate>Sat, 07 Jan 2023 10:54:37 +0800</pubDate><guid>https://www.xlabs.club/docs/java/migrating-spring-to-spring-boot/</guid><description>从 Spring 到 Spring Boot，迁移升级快速入门以及各种踩坑记录。
概述 从 Spring 到 Spring Boot，整体开发、运行方式主要变化。
- 当前（老）模式 新模式（本地） 新模式（线上） 开发习惯 Spring + 外置 Tomcat Spring Boot（embed tomcat） Spring Boot War or Jar Java 版本 8、11、16、17 11、17（推荐）、21 11、17（推荐）、21 Tomcat 版本 8.x、9.x 9.x 9.x（推荐）、10.x 说明：
理论上支持 Java11，但是要求业务方尽量使用 Java17。其他版本都是实验性质尽量兼容。 线上运行支持 Spring Boot jar 直接运行，但主要业务仍推荐以 war + tomcat 为主。如果希望以 java -jar 方式运行，参考下面的章节“jar 方式运行”描述。 目前 Spring Boot 主要推行版本是 2.7.x。 3.x 版本逐渐适配中。 快速开始 线下支撑系统导航，点击 脚手架 进入 spring start 页面，按自己需求选择模块，生成自己业务模式初始化代码。 写（Copy）业务代码到项目里，修改 pom.</description></item></channel></rss>